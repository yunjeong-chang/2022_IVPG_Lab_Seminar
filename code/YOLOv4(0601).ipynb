{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunjeong-chang/2022_IVPG_Lab_Seminar/blob/main/code/YOLOv4(0601).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrLFyTlHqfs_"
      },
      "source": [
        "# default setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4GCks7vmNXD",
        "outputId": "bd1e3ed4-86b2-4ad3-bb70-9bb5064eebcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov3/TensorFlow-2.x-YOLOv3\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/yolov3/TensorFlow-2.x-YOLOv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OiR3OAMqkse"
      },
      "outputs": [],
      "source": [
        "#Ï†ÑÏ≤¥Ï†ÅÏúºÎ°ú ÌïÑÏöîÌïú Í≤ÉÎì§ import\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, ZeroPadding2D, BatchNormalization, MaxPool2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import colorsys\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwoSS9z-pzSu"
      },
      "source": [
        "# Load_Yolo_model() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96vpu9LEp-8k"
      },
      "source": [
        "### Create_Yolo()üåü"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQo1GmLop6V_"
      },
      "outputs": [],
      "source": [
        "def read_class_names(class_file_name):\n",
        "    # loads class name from a file\n",
        "    names = {}\n",
        "    with open(class_file_name, 'r') as data:\n",
        "        for ID, name in enumerate(data):\n",
        "            names[ID] = name.strip('\\n')\n",
        "    return names\n",
        "\n",
        "def mish(x):\n",
        "    return x * tf.math.tanh(tf.math.softplus(x))\n",
        "\n",
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n",
        "    if downsample:\n",
        "      input_layer = ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "      padding = 'valid'\n",
        "      strides = 2\n",
        "    else:\n",
        "      strides = 1\n",
        "      padding = 'same'\n",
        "\n",
        "    conv = Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides,\n",
        "                  padding=padding, use_bias=not bn, kernel_regularizer=l2(0.0005),\n",
        "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
        "    if bn:\n",
        "        conv = BatchNormalization()(conv)\n",
        "    if activate == True:\n",
        "        if activate_type == \"leaky\":\n",
        "            conv = LeakyReLU(alpha=0.1)(conv)\n",
        "        elif activate_type == \"mish\":\n",
        "            conv = mish(conv) \n",
        "\n",
        "    return conv\n",
        "\n",
        "def residual_block(input_layer, input_channel, filter_num1, filter_num2, activate_type='leaky'):\n",
        "    short_cut = input_layer\n",
        "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1), activate_type=activate_type)\n",
        "    conv = convolutional(conv, filters_shape=(3, 3, filter_num1, filter_num2), activate_type=activate_type)\n",
        "    residual_output = short_cut + conv\n",
        "    return residual_output\n",
        "\n",
        "#import pdb;pdb.set_trace()\n",
        "\n",
        "def cspdarknet53(input_data):\n",
        "  \n",
        "  input_data = convolutional(input_data, (3, 3, 3, 32), activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (3, 3, 32, 64), downsample=True, activate_type=\"mish\")\n",
        "\n",
        "  route = input_data\n",
        "  route = convolutional(route, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "\n",
        "  input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "  for i in range(1):\n",
        "    input_data = residual_block(input_data, 64, 32, 64, activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "\n",
        "  input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "  input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (3, 3, 64, 128), downsample=True, activate_type=\"mish\")\n",
        "\n",
        "  route = input_data\n",
        "  route = convolutional(route, (1, 1, 128, 64), activate_type=\"mish\")\n",
        "  \n",
        "  input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n",
        "  for i in range(2):\n",
        "    input_data = residual_block(input_data, 64,  64, 64, activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "\n",
        "  input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "  input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True, activate_type=\"mish\")\n",
        "  \n",
        "  route = input_data\n",
        "  route = convolutional(route, (1, 1, 256, 128), activate_type=\"mish\")\n",
        "    \n",
        "  input_data = convolutional(input_data, (1, 1, 256, 128), activate_type=\"mish\")\n",
        "  for i in range(8):\n",
        "    input_data = residual_block(input_data, 128, 128, 128, activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n",
        "  \n",
        "  input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "  input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n",
        "  route_1 = input_data\n",
        "  \n",
        "  input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True, activate_type=\"mish\")\n",
        "  \n",
        "  route = input_data\n",
        "  route = convolutional(route, (1, 1, 512, 256), activate_type=\"mish\")\n",
        "  \n",
        "  input_data = convolutional(input_data, (1, 1, 512, 256), activate_type=\"mish\")\n",
        "  for i in range(8):\n",
        "    input_data = residual_block(input_data, 256, 256, 256, activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n",
        "  \n",
        "  input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "  input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n",
        "  route_2 = input_data\n",
        "    \n",
        "  input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True, activate_type=\"mish\")\n",
        "  \n",
        "  route = input_data\n",
        "  route = convolutional(route, (1, 1, 1024, 512), activate_type=\"mish\")\n",
        "  \n",
        "  input_data = convolutional(input_data, (1, 1, 1024, 512), activate_type=\"mish\")\n",
        "  for i in range(4):\n",
        "    input_data = residual_block(input_data, 512, 512, 512, activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n",
        "  \n",
        "  input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "  input_data = convolutional(input_data, (1, 1, 1024, 1024), activate_type=\"mish\")\n",
        "  input_data = convolutional(input_data, (1, 1, 1024, 512))\n",
        "  input_data = convolutional(input_data, (3, 3, 512, 1024))\n",
        "  input_data = convolutional(input_data, (1, 1, 1024, 512))\n",
        "\n",
        "  max_pooling_1 = tf.keras.layers.MaxPool2D(pool_size=13, padding='SAME', strides=1)(input_data)\n",
        "  max_pooling_2 = tf.keras.layers.MaxPool2D(pool_size=9, padding='SAME', strides=1)(input_data)\n",
        "  max_pooling_3 = tf.keras.layers.MaxPool2D(pool_size=5, padding='SAME', strides=1)(input_data)\n",
        "  input_data = tf.concat([max_pooling_1, max_pooling_2, max_pooling_3, input_data], axis=-1)\n",
        "\n",
        "  input_data = convolutional(input_data, (1, 1, 2048, 512))\n",
        "  input_data = convolutional(input_data, (3, 3, 512, 1024))\n",
        "  input_data = convolutional(input_data, (1, 1, 1024, 512))\n",
        "\n",
        "  return route_1, route_2, input_data  \n",
        "\n",
        "def upsample(input_layer):\n",
        "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')\n",
        "\n",
        "def YOLOv4(input_layer, NUM_CLASS):\n",
        "  route_1, route_2, conv = cspdarknet53(input_layer)\n",
        "\n",
        "  route = conv\n",
        "  conv = convolutional(conv, (1, 1, 512, 256))\n",
        "  conv = upsample(conv)\n",
        "  route_2 = convolutional(route_2, (1, 1, 512, 256))\n",
        "  conv = tf.concat([route_2, conv], axis=-1)\n",
        "\n",
        "  conv = convolutional(conv, (1, 1, 512, 256))\n",
        "  conv = convolutional(conv, (3, 3, 256, 512))\n",
        "  conv = convolutional(conv, (1, 1, 512, 256))\n",
        "  conv = convolutional(conv, (3, 3, 256, 512))\n",
        "  conv = convolutional(conv, (1, 1, 512, 256))\n",
        "  route_2 = conv\n",
        "  conv = convolutional(conv, (1, 1, 256, 128))\n",
        "  conv = upsample(conv)\n",
        "  route_1 = convolutional(route_1, (1, 1, 256, 128))\n",
        "  conv = tf.concat([route_1, conv], axis=-1)\n",
        "\n",
        "  conv = convolutional(conv, (1, 1, 256, 128))\n",
        "  conv = convolutional(conv, (3, 3, 128, 256))\n",
        "  conv = convolutional(conv, (1, 1, 256, 128))\n",
        "  conv = convolutional(conv, (3, 3, 128, 256))\n",
        "  conv = convolutional(conv, (1, 1, 256, 128))\n",
        "  route_1 = conv\n",
        "  conv = convolutional(conv, (3, 3, 128, 256))\n",
        "  conv_sbbox = convolutional(conv, (1, 1, 256, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "  conv = convolutional(route_1, (3, 3, 128, 256), downsample=True)\n",
        "  conv = tf.concat([conv, route_2], axis=-1)\n",
        "  conv = convolutional(conv, (1, 1, 512, 256))\n",
        "  conv = convolutional(conv, (3, 3, 256, 512))\n",
        "  conv = convolutional(conv, (1, 1, 512, 256))\n",
        "  conv = convolutional(conv, (3, 3, 256, 512))\n",
        "  conv = convolutional(conv, (1, 1, 512, 256))\n",
        "  route_2 = conv\n",
        "  conv = convolutional(conv, (3, 3, 256, 512))\n",
        "  conv_mbbox = convolutional(conv, (1, 1, 512, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "  conv = convolutional(route_2, (3, 3, 256, 512), downsample=True)\n",
        "  conv = tf.concat([conv, route], axis=-1)\n",
        "  conv = convolutional(conv, (1, 1, 1024, 512))\n",
        "  conv = convolutional(conv, (3, 3, 512, 1024))\n",
        "  conv = convolutional(conv, (1, 1, 1024, 512))\n",
        "  conv = convolutional(conv, (3, 3, 512, 1024))\n",
        "  conv = convolutional(conv, (1, 1, 1024, 512))\n",
        "  conv = convolutional(conv, (3, 3, 512, 1024))\n",
        "  conv_lbbox = convolutional(conv, (1, 1, 1024, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "  return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
        "\n",
        "def decode(conv_output, NUM_CLASS, i=0): \n",
        "    conv_shape = tf.shape(conv_output)\n",
        "    batch_size = conv_shape[0]\n",
        "    output_size = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_dxdy, conv_raw_dwdh, conv_raw_conf, conv_raw_prob = tf.split(conv_output, (2, 2, 1, NUM_CLASS), axis=-1)\n",
        "\n",
        "    xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n",
        "    xy_grid = tf.expand_dims(tf.stack(xy_grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
        "    xy_grid = tf.tile(tf.expand_dims(xy_grid, axis=0), [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "    \n",
        "    YOLO_STRIDES = [8, 16, 32]\n",
        "    #9Í∞úÏùò Anchors\n",
        "    YOLO_ANCHORS = [[[10, 13], [16, 30], [33, 23]], [[30, 61], [62, 45], [59, 119]], [[116, 90], [156, 198], [373, 326]]]\n",
        "\n",
        "    STRIDES = np.array(YOLO_STRIDES)\n",
        "    ANCHORS = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
        "\n",
        "    # prediction boxÏùò Ï§ëÏã¨ ÏúÑÏπò ÏòàÏ∏°\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
        "\n",
        "    # prediction boxÏùò ÎÑàÎπÑÏôÄ ÎÜíÏù¥ ÏòàÏ∏°\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
        "\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf) # confidence Í≥ÑÏÇ∞\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob) # probability Í≥ÑÏÇ∞\n",
        "\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
        "\n",
        "def Create_Yolo(input_size=416, channels=3, training=False, CLASSES=\"model_data/coco/coco.names\"):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    input_layer = Input([input_size, input_size, channels])\n",
        "\n",
        "    #yolov3\n",
        "    #conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
        "\n",
        "    #yolov4\n",
        "    conv_tensors = YOLOv4(input_layer, NUM_CLASS)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_tensor in enumerate(conv_tensors):\n",
        "      pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
        "      if training : \n",
        "        output_tensors.append(conv_tensor)\n",
        "      output_tensors.append(pred_tensor)\n",
        "\n",
        "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
        "\n",
        "    return Yolo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu3cKt60rd8Z"
      },
      "source": [
        "### load_yolo_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq39U1JwrhKR"
      },
      "outputs": [],
      "source": [
        "def load_yolo_weights(model, weights_file):\n",
        "    tf.keras.backend.clear_session() \n",
        "\n",
        "    #yolov3\n",
        "    #range1 = 75 \n",
        "    #range2 = [58, 66, 74]\n",
        "\n",
        "    #yolov4\n",
        "    range1 = 110 \n",
        "    range2 = [93, 101, 109] \n",
        "    \n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(range1):\n",
        "            if i > 0:\n",
        "                conv_layer_name = 'conv2d_%d' %i\n",
        "            else:\n",
        "                conv_layer_name = 'conv2d'\n",
        "                \n",
        "            if j > 0:\n",
        "                bn_layer_name = 'batch_normalization_%d' %j\n",
        "            else:\n",
        "                bn_layer_name = 'batch_normalization'\n",
        "            \n",
        "            conv_layer = model.get_layer(conv_layer_name)\n",
        "            filters = conv_layer.filters\n",
        "            k_size = conv_layer.kernel_size[0]\n",
        "            in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "            if i not in range2:\n",
        "                # darknet weights: [beta, gamma, mean, variance]\n",
        "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "                # tf weights: [gamma, beta, mean, variance]\n",
        "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "                bn_layer = model.get_layer(bn_layer_name)\n",
        "                j += 1\n",
        "            else:\n",
        "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "\n",
        "            # darknet shape (out_dim, in_dim, height, width)\n",
        "            conv_shape = (filters, in_dim, k_size, k_size)\n",
        "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
        "            # tf shape (height, width, in_dim, out_dim)\n",
        "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "\n",
        "            if i not in range2:\n",
        "                conv_layer.set_weights([conv_weights])\n",
        "                bn_layer.set_weights(bn_weights)\n",
        "            else:\n",
        "                conv_layer.set_weights([conv_weights, conv_bias])\n",
        "\n",
        "        assert len(wf.read()) == 0, 'failed to read all data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZZZ5bmYqEw-"
      },
      "source": [
        "### Load_Yolo_model() üåü\n",
        "<ÌïÑÏöîÌïú Ìï®Ïàò>\n",
        "1. Create_Yolo() : yolov4Ïùò Íµ¨Ï°∞Î•º ÎßåÎìúÎäî Ìï®Ïàò\n",
        "2. load_yolo_weights() : Darknet weights Î∂àÎü¨Ïò§Îäî Ìï®Ïàò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmsLjdvgqKIO"
      },
      "outputs": [],
      "source": [
        "def Load_Yolo_model(): \n",
        "\n",
        "    #gpuÍ¥ÄÎ†®Îêú Î∂ÄÎ∂Ñ\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if len(gpus) > 0:\n",
        "        print(f'GPUs {gpus}')\n",
        "        try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        except RuntimeError: pass\n",
        "\n",
        "    #yolov3\n",
        "    #YOLO_V3_WEIGHTS = \"model_data/yolov3.weights\"\n",
        "    #Darknet_weights = YOLO_V3_WEIGHTS\n",
        "\n",
        "    #yolov4\n",
        "    YOLO_V4_WEIGHTS = \"model_data/yolov4.weights\"\n",
        "    Darknet_weights = YOLO_V4_WEIGHTS\n",
        "\n",
        "    print(\"Loading Darknet_weights from:\", Darknet_weights)\n",
        "\n",
        "    YOLO_INPUT_SIZE = 416\n",
        "    YOLO_COCO_CLASSES = \"model_data/coco/coco.names\"\n",
        "\n",
        "    #Create_Yolo Ìï®Ïàò\n",
        "    yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
        "    #load_yolo_weights Ìï®Ïàò\n",
        "    load_yolo_weights(yolo, Darknet_weights) \n",
        "\n",
        "    return yolo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7--HZUSgp63p"
      },
      "source": [
        "# detect_image() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLEvkBwAsq0b"
      },
      "source": [
        "### detect_image()ÏóêÏÑú ÌïÑÏöîÌïú ÎÇòÎ®∏ÏßÄ Ìï®ÏàòÎì§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt3doWYBsvQ6"
      },
      "outputs": [],
      "source": [
        "def image_preprocess(image, target_size, gt_boxes=None):\n",
        "    ih, iw = target_size\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    scale = min(iw/w, ih/h)\n",
        "    nw, nh = int(scale * w), int(scale * h)\n",
        "    image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
        "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
        "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
        "    image_paded = image_paded / 255.\n",
        "\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
        "        return image_paded, gt_boxes\n",
        "\n",
        "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
        "    valid_scale = [0, np.inf]\n",
        "    pred_bbox = np.array(pred_bbox)\n",
        "\n",
        "    pred_xywh = pred_bbox[:, 0:4]\n",
        "    pred_conf = pred_bbox[:, 4]\n",
        "    pred_prob = pred_bbox[:, 5:]\n",
        "\n",
        "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
        "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
        "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
        "    \n",
        "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
        "    org_h, org_w = original_image.shape[:2]\n",
        "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
        "\n",
        "    dw = (input_size - resize_ratio * org_w) / 2\n",
        "    dh = (input_size - resize_ratio * org_h) / 2\n",
        "\n",
        "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
        "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
        "\n",
        "    # 3. clip some boxes those are out of range\n",
        "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
        "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
        "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
        "    pred_coor[invalid_mask] = 0\n",
        "\n",
        "    # 4. discard some invalid boxes\n",
        "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
        "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
        "\n",
        "    # 5. discard boxes with low scores\n",
        "    classes = np.argmax(pred_prob, axis=-1)\n",
        "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
        "    score_mask = scores > score_threshold\n",
        "    mask = np.logical_and(scale_mask, score_mask)\n",
        "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
        "\n",
        "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)\n",
        "\n",
        "def draw_bbox(image, bboxes, CLASSES=\"model_data/coco/coco.names\", show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
        "    NUM_CLASS = read_class_names(CLASSES)\n",
        "    num_classes = len(NUM_CLASS)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    #print(\"hsv_tuples\", hsv_tuples)\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    random.seed(0)\n",
        "    random.shuffle(colors)\n",
        "    random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        score = bbox[4]\n",
        "        class_ind = int(bbox[5])\n",
        "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
        "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
        "        if bbox_thick < 1: bbox_thick = 1\n",
        "        fontScale = 0.75 * bbox_thick\n",
        "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
        "\n",
        "        # put object rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
        "\n",
        "        if show_label:\n",
        "            # get text label\n",
        "            score_str = \" {:.2f}\".format(score) if show_confidence else \"\"\n",
        "\n",
        "            if tracking: score_str = \" \"+str(score)\n",
        "\n",
        "            try:\n",
        "                label = \"{}\".format(NUM_CLASS[class_ind]) + score_str\n",
        "            except KeyError:\n",
        "                print(\"You received KeyError, this might be that you are trying to use yolo original weights\")\n",
        "                print(\"while using custom classes, if using custom model in configs.py set YOLO_CUSTOM_WEIGHTS = True\")\n",
        "\n",
        "            # get text size\n",
        "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                                                                  fontScale, thickness=bbox_thick)\n",
        "            # put filled text rectangle\n",
        "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
        "\n",
        "            # put text above rectangle\n",
        "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmY-brVvqKlq"
      },
      "source": [
        "### nms() üåü"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvmzXdFWp8qP"
      },
      "outputs": [],
      "source": [
        "def bboxes_iou(boxes1, boxes2):\n",
        "    boxes1 = np.array(boxes1)\n",
        "    boxes2 = np.array(boxes2)\n",
        "    #import pdb;pdb.set_trace()\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "    ious = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
        "\n",
        "    return ious\n",
        "\n",
        "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
        "    classes_in_img = list(set(bboxes[:, 5]))\n",
        "    best_bboxes = []\n",
        "    #import pdb;pdb.set_trace()\n",
        "\n",
        "    for cls in classes_in_img:\n",
        "      cls_mask = (bboxes[:, 5] == cls)\n",
        "      cls_bboxes = bboxes[cls_mask]\n",
        "      # Process 1: bounding boxes\bÏùò ÏàòÍ∞Ä 0Î≥¥Îã§ ÌÅ∞ÏßÄ ÌôïÏù∏\n",
        "      while len(cls_bboxes) > 0: \n",
        "        # Process 2: Í∞ÄÏû• ÎÜíÏùÄ Ï†êÏàòÎ•º Í∞ÄÏßÑ bounding boxes\b ÏÑ†ÌÉù\n",
        "        max_ind = np.argmax(cls_bboxes[:, 4])\n",
        "        best_bbox = cls_bboxes[max_ind]\n",
        "        best_bboxes.append(best_bbox)\n",
        "        cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
        "        # Process 3: bboxes_iou Ìï®Ïàò - iouÍ∞íÏù¥ thresholdÎ≥¥Îã§ ÎÜíÏùÄ bounding boxÎäî Ï†úÍ±∞\n",
        "        iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
        "        weight = np.ones((len(iou),), dtype=np.float32)\n",
        "\n",
        "        assert method in ['nms', 'soft-nms']\n",
        "        if method == 'nms':\n",
        "          iou_mask = iou > iou_threshold\n",
        "          weight[iou_mask] = 0.0\n",
        "        if method == 'soft-nms':\n",
        "          weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
        "\n",
        "        cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
        "        score_mask = cls_bboxes[:, 4] > 0.\n",
        "        cls_bboxes = cls_bboxes[score_mask]\n",
        "\n",
        "    return best_bboxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwD0bd8PqMu3"
      },
      "source": [
        "### detect_image()\n",
        "<ÌïÑÏöîÌïú Ìï®Ïàò>\n",
        "1. image_preprocess()\n",
        "2. postprocess_boxes()\n",
        "3. nms(), bboxes_iou()\n",
        "4. draw_bbox()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UisSkbYDqNI7"
      },
      "outputs": [],
      "source": [
        "def detect_image(Yolo, image_path, output_path, input_size=416, show=False, CLASSES=\"model_data/coco/coco.names\", score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
        "    original_image = cv2.imread(image_path)\n",
        "    #original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    #original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "    \n",
        "    #YOLO_FRAMEWORK == \"tf\"\n",
        "    pred_bbox = Yolo.predict(image_data)\n",
        "        \n",
        "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "    \n",
        "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "    #import pdb;pdb.set_trace()\n",
        "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "    \n",
        "    if output_path != '': cv2.imwrite(output_path, image)\n",
        "    if show:\n",
        "      #cv2.imshow(\"predicted image\", image)\n",
        "      cv2.waitKey(0)\n",
        "      cv2.destroyAllWindows()\n",
        "        \n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYZ9r-hxn5gv"
      },
      "source": [
        "# detection_demo.py üåü\n",
        "<ÌïÑÏöîÌïú Ìï®Ïàò>\n",
        "1. Load_Yolo_model() : yolov4Ïùò Íµ¨Ï°∞Î•º ÎßåÎì§Í≥†, weightsÎ•º Î∂àÎü¨Ïò§Îäî Ìï®Ïàò\n",
        "2. detect_image() : Ïù¥ÎØ∏ÏßÄÎ•º yolov4 Î™®Îç∏Ïóê ÌÉúÏö∞Í≥†, nms ÏßÑÌñâÌïú ÌõÑ ÏµúÏ¢Ö Í≤∞Í≥º Î∞ïÏä§Îì§ÏùÑ Í∑∏Î¶¨Îäî Ìï®Ïàò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBqyOM8TnEkm"
      },
      "outputs": [],
      "source": [
        "#detection_demo.py\n",
        "\n",
        "yolo = Load_Yolo_model()\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/yolov3/TensorFlow-2.x-YOLOv3/IMAGES/city.jpg\"\n",
        "output_path = \"/content/drive/MyDrive/yolov3/TensorFlow-2.x-YOLOv3/IMAGES/city_pred.jpg\"\n",
        "image = detect_image(yolo, image_path, output_path, input_size=416, show=True, rectangle_colors=(255,0,0))\n",
        "\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(30,15))\n",
        "\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolo.summary()"
      ],
      "metadata": {
        "id": "9AEm7sTAy1ii"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BrLFyTlHqfs_",
        "96vpu9LEp-8k",
        "Eu3cKt60rd8Z",
        "7--HZUSgp63p",
        "uLEvkBwAsq0b",
        "mmY-brVvqKlq",
        "lwD0bd8PqMu3"
      ],
      "name": "YOLOv4(0601).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}